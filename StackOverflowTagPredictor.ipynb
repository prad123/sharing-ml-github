{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   1  How to check if an uploaded file is an image w...   \n",
       "1   2  How can I prevent firefox from closing when I ...   \n",
       "2   3           R Error Invalid type (list) for variable   \n",
       "3   4      How do I replace special characters in a URL?   \n",
       "4   5               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.append(df.iloc[[4,10, 4]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 4 columns):\n",
      "Id       50000 non-null int64\n",
      "Title    50000 non-null object\n",
      "Body     50000 non-null object\n",
      "Tags     50000 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df2.drop([\"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  How to check if an uploaded file is an image w...   \n",
       "1  How can I prevent firefox from closing when I ...   \n",
       "2           R Error Invalid type (list) for variable   \n",
       "3      How do I replace special characters in a URL?   \n",
       "4               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_no_dup = df2[df2.duplicated() == False]\n",
    "df.drop([\"Id\"], inplace = True, axis=1)\n",
    "df_no_dup = df[df.duplicated() == False]\n",
    "df_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate entries:  143 ( 0.28599999999999737 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of duplicate entries: \", len(df) - len(df_no_dup), \"(\",(1 - len(df_no_dup)/len(df))*100,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  How to check if an uploaded file is an image w...   \n",
       "1  How can I prevent firefox from closing when I ...   \n",
       "2           R Error Invalid type (list) for variable   \n",
       "3      How do I replace special characters in a URL?   \n",
       "4               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  tag_count  \n",
       "0  php image-processing file-upload upload mime-t...          5  \n",
       "1                                            firefox          1  \n",
       "2                          r matlab machine-learning          3  \n",
       "3                                    c# url encoding          3  \n",
       "4                          php api file-get-contents          3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df.Tags.apply(lambda))\n",
    "df_no_dup[\"tag_count\"] = df_no_dup.Tags.apply(lambda x: len(x.split()))\n",
    "df_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    14436\n",
       "2    13233\n",
       "4     9536\n",
       "1     6827\n",
       "5     5825\n",
       "Name: tag_count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup.tag_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_dup = df_no_dup.drop([\"tag_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectorizer = CountVectorizer()\n",
    "tag_vectors = tag_vectorizer.fit_transform(df_no_dup.Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag dimension:  10034\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag dimension: \", len(tag_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_doc_freq = dict(zip(tag_vectorizer.get_feature_names(), tag_vectors.sum(axis=0).A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10034"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((tag_doc_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radiobuttonlist</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catalyst</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unity3d</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tags  Count\n",
       "0            where     10\n",
       "1  radiobuttonlist      2\n",
       "2             egit      2\n",
       "3         catalyst      4\n",
       "4          unity3d     16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame.from_dict(tag_doc_freq, orient='index')\n",
    "tags_df.reset_index(level=0, inplace=True)\n",
    "tags_df.columns = [\"Tags\", \"Count\"]\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>net</td>\n",
       "      <td>4489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>java</td>\n",
       "      <td>3639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>android</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>php</td>\n",
       "      <td>3325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>javascript</td>\n",
       "      <td>3230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tags  Count\n",
       "2734         net   4489\n",
       "6982        java   3639\n",
       "5511     android   3563\n",
       "7751         php   3325\n",
       "4092  javascript   3230"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.title(\"Tag Distribution\")\n",
    "# plt.plot(tags_df.Count.sort_values(ascending=False).values)\n",
    "# plt.xlabel(\"num\")\n",
    "# plt.ylabel(\"freq\")\n",
    "# plt.show()\n",
    "\n",
    "# df_tags_sorted_by_freq = tags_df.sort()\n",
    "# plt.title(\"Tag Distribution\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# tags_df.Count.sort_values(ascending=False).index\n",
    "tags_df_sorted_by_freq = tags_df.iloc[tags_df.Count.sort_values(ascending=False).index]\n",
    "tags_df_sorted_by_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "tags_df_sorted_by_freq.head(30).plot(kind=\"bar\")\n",
    "plt.title(\"Tag Distribution\")\n",
    "plt.xticks(np.arange(0,30), tags_df_sorted_by_freq.Tags)\n",
    "plt.xlabel(\"num\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer    = PorterStemmer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    title         = text[0].encode('utf-8')\n",
    "    code_in_ques  = ''.join(re.findall('<code>(.*?)</code>',text[1], flags=re.MULTILINE|re.DOTALL))\n",
    "    ques_reminder = BeautifulSoup(re.sub('<code>(.*?)</code>','', text[1], flags=re.MULTILINE|re.DOTALL), \"lxml\").text\n",
    "    \n",
    "    ques = str(title)+\" \"+str(title)+\" \"+str(title) + \" \" + str(ques_reminder)\n",
    "    ques = re.sub(r'[^A-Za-z]+', ' ', ques)\n",
    "    \n",
    "    ques = ' '.join(list(map(stemmer.stem, [word for word in word_tokenize(ques.lower()) if word not in stop_words and len(word) > 1 or word == 'c'] )))\n",
    "    \n",
    "    return pd.Series([ques, code_in_ques, text[2], '<code>' in text[1]], index=['Ques', 'Code', 'Tags', 'is_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dx = df_no_dup[4:5].apply(lambda x: normalize_text(x), axis=1)\n",
    "# df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(columns=[\"Ques\", \"Code\", \"Tags\", \"is_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_norm = pd.DataFrame(df_no_dup.apply(lambda x: normalize_text(x), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ques</th>\n",
       "      <th>Code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>is_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>check upload file imag without mime type check...</td>\n",
       "      <td></td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prevent firefox close press ctrl prevent firef...</td>\n",
       "      <td></td>\n",
       "      <td>firefox</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>error invalid type list variabl error invalid ...</td>\n",
       "      <td>Error in model.frame.default(formula = expert_...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>replac special charact url replac special char...</td>\n",
       "      <td></td>\n",
       "      <td>c# url encoding</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modifi whoi contact detail modifi whoi contact...</td>\n",
       "      <td>function modify(.......)\\n{\\n  $mcontact = fil...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Ques  \\\n",
       "0  check upload file imag without mime type check...   \n",
       "1  prevent firefox close press ctrl prevent firef...   \n",
       "2  error invalid type list variabl error invalid ...   \n",
       "3  replac special charact url replac special char...   \n",
       "4  modifi whoi contact detail modifi whoi contact...   \n",
       "\n",
       "                                                Code  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Error in model.frame.default(formula = expert_...   \n",
       "3                                                      \n",
       "4  function modify(.......)\\n{\\n  $mcontact = fil...   \n",
       "\n",
       "                                                Tags  is_code  \n",
       "0  php image-processing file-upload upload mime-t...    False  \n",
       "1                                            firefox    False  \n",
       "2                          r matlab machine-learning     True  \n",
       "3                                    c# url encoding    False  \n",
       "4                          php api file-get-contents     True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary=True)\n",
    "tag_vectors = tag_vectorizer.fit_transform(df_norm.Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13892"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_choose(n):\n",
    "    return np.argpartition(tag_vectors.sum(axis=0).tolist()[0], -n)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_to_choose(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_frequent_tags = tags_to_choose(4)\n",
    "# tag_vectors[:,most_frequent_tags].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_explained = []\n",
    "total_ques = len(df_no_dup)\n",
    "for i in range(1, len(tag_vectorizer.get_feature_names()), 5):#increase range for final implementation\n",
    "    num_ques_with_tags = np.count_nonzero(tag_vectors[:,tags_to_choose(i)].sum(axis=1))\n",
    "    ques_explained.append(np.round((num_ques_with_tags/total_ques)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ques_explained)\n",
    "plt.xlabel(\"num tags\")\n",
    "plt.ylabel(\"% of Questions covered\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trade-off: compute time vs. %of questions covered\n",
    "finalist_tags = tag_vectors[:,tags_to_choose(250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(df_norm[[\"Ques\", \"is_code\"]], finalist_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# feature_vectorizer = CountVectorizer(ngram_range=(1,4), max_features=2000, max_df=0.9, min_df=0.1, binary=True)\n",
    "feature_vectorizer = CountVectorizer(ngram_range=(1,4), max_features=2000, binary=True)\n",
    "feat_train_ngram = feature_vectorizer.fit_transform(features_train['Ques'])\n",
    "feat_test_ngram  = feature_vectorizer.transform(features_test['Ques'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_train_ngram[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model = OneVsRestClassifier(LogisticRegressionCV(Cs=3,  n_jobs=-1, penalty = \"l2\", solver=\"saga\", refit = True, multi_class=\"ovr\"))\n",
    "model = OneVsRestClassifier(SGDClassifier(loss='hinge'))\n",
    "model.fit(feat_train_ngram, target_train)\n",
    "\n",
    "# model = OneVsRestClassifier(LogisticRegression(n_jobs=-1, penalty = \"l2\", solver=\"saga\", multi_class=\"ovr\"))\n",
    "# model.fit(feat_train_ngram, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.24298034496590454\n",
      "macro f1 score : 0.2500678526254982\n",
      "micro f1 scoore : 0.42046309454150294\n",
      "hamming loss : 0.005561973525872443\n",
      "Precision recall report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.75      0.14      0.23        22\n",
      "          2       0.14      0.12      0.13         8\n",
      "          3       0.85      0.46      0.59        24\n",
      "          4       0.25      0.06      0.10        16\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.00      0.00      0.00        21\n",
      "          7       0.00      0.00      0.00         9\n",
      "          8       0.33      0.06      0.10        17\n",
      "          9       0.00      0.00      0.00        14\n",
      "         10       0.50      0.08      0.13        13\n",
      "         11       0.12      0.06      0.08        18\n",
      "         12       0.00      0.00      0.00        17\n",
      "         13       0.00      0.00      0.00        17\n",
      "         14       0.14      0.05      0.08        19\n",
      "         15       0.00      0.00      0.00        15\n",
      "         16       0.25      0.08      0.12        12\n",
      "         17       0.75      0.14      0.23        22\n",
      "         18       0.29      0.12      0.17        17\n",
      "         19       0.41      0.39      0.40        18\n",
      "         20       0.17      0.06      0.08        18\n",
      "         21       0.60      0.14      0.23        21\n",
      "         22       0.50      0.11      0.18        18\n",
      "         23       0.00      0.00      0.00        16\n",
      "         24       1.00      0.04      0.07        26\n",
      "         25       0.00      0.00      0.00        18\n",
      "         26       0.25      0.06      0.09        18\n",
      "         27       0.67      0.42      0.52        19\n",
      "         28       0.45      0.25      0.32        20\n",
      "         29       0.00      0.00      0.00        15\n",
      "         30       0.29      0.18      0.22        11\n",
      "         31       0.50      0.04      0.08        24\n",
      "         32       0.62      0.28      0.38        18\n",
      "         33       0.00      0.00      0.00        11\n",
      "         34       0.00      0.00      0.00        15\n",
      "         35       0.00      0.00      0.00        12\n",
      "         36       1.00      0.05      0.10        20\n",
      "         37       0.00      0.00      0.00        19\n",
      "         38       0.70      0.37      0.48        19\n",
      "         39       0.50      0.29      0.36        14\n",
      "         40       1.00      0.33      0.50        15\n",
      "         41       0.00      0.00      0.00        21\n",
      "         42       0.40      0.11      0.17        19\n",
      "         43       0.40      0.17      0.24        12\n",
      "         44       0.00      0.00      0.00        18\n",
      "         45       0.50      0.24      0.32        17\n",
      "         46       0.43      0.23      0.30        13\n",
      "         47       0.00      0.00      0.00        20\n",
      "         48       0.75      0.20      0.32        15\n",
      "         49       0.33      0.05      0.09        20\n",
      "         50       0.00      0.00      0.00        29\n",
      "         51       0.12      0.05      0.07        19\n",
      "         52       0.00      0.00      0.00        15\n",
      "         53       0.25      0.04      0.07        23\n",
      "         54       0.50      0.05      0.08        22\n",
      "         55       0.00      0.00      0.00        17\n",
      "         56       0.00      0.00      0.00        20\n",
      "         57       0.33      0.05      0.09        20\n",
      "         58       0.25      0.04      0.07        24\n",
      "         59       0.22      0.09      0.12        23\n",
      "         60       0.14      0.05      0.07        22\n",
      "         61       0.25      0.05      0.08        22\n",
      "         62       0.57      0.55      0.56        22\n",
      "         63       0.50      0.05      0.09        21\n",
      "         64       0.64      0.30      0.41        23\n",
      "         65       0.00      0.00      0.00        19\n",
      "         66       0.00      0.00      0.00        23\n",
      "         67       0.00      0.00      0.00        19\n",
      "         68       0.75      0.17      0.27        18\n",
      "         69       0.00      0.00      0.00        22\n",
      "         70       0.00      0.00      0.00        22\n",
      "         71       0.21      0.14      0.17        21\n",
      "         72       0.00      0.00      0.00        20\n",
      "         73       0.00      0.00      0.00        15\n",
      "         74       0.31      0.38      0.34        24\n",
      "         75       0.57      0.57      0.57        21\n",
      "         76       0.33      0.10      0.16        29\n",
      "         77       0.53      0.33      0.41        24\n",
      "         78       0.46      0.21      0.29        29\n",
      "         79       0.14      0.05      0.07        22\n",
      "         80       0.33      0.06      0.10        17\n",
      "         81       0.50      0.19      0.28        26\n",
      "         82       0.20      0.05      0.08        21\n",
      "         83       0.29      0.06      0.11        31\n",
      "         84       0.14      0.10      0.11        21\n",
      "         85       0.00      0.00      0.00        33\n",
      "         86       0.41      0.36      0.38        39\n",
      "         87       0.40      0.46      0.43        26\n",
      "         88       0.81      0.57      0.67        23\n",
      "         89       0.33      0.04      0.07        26\n",
      "         90       0.20      0.03      0.06        29\n",
      "         91       0.00      0.00      0.00        23\n",
      "         92       0.00      0.00      0.00        25\n",
      "         93       0.00      0.00      0.00        31\n",
      "         94       0.00      0.00      0.00        17\n",
      "         95       0.52      0.58      0.55        26\n",
      "         96       0.80      0.20      0.32        20\n",
      "         97       0.00      0.00      0.00        27\n",
      "         98       0.00      0.00      0.00        30\n",
      "         99       0.17      0.04      0.06        27\n",
      "        100       0.00      0.00      0.00        31\n",
      "        101       0.38      0.19      0.26        26\n",
      "        102       0.67      0.08      0.15        24\n",
      "        103       0.69      0.75      0.72        24\n",
      "        104       0.82      0.47      0.60        30\n",
      "        105       0.00      0.00      0.00        16\n",
      "        106       0.00      0.00      0.00        34\n",
      "        107       0.50      0.22      0.30        23\n",
      "        108       0.56      0.36      0.44        25\n",
      "        109       0.31      0.15      0.20        27\n",
      "        110       0.60      0.12      0.20        25\n",
      "        111       0.30      0.12      0.18        24\n",
      "        112       0.89      0.76      0.82        21\n",
      "        113       0.57      0.36      0.44        33\n",
      "        114       0.33      0.04      0.07        25\n",
      "        115       0.00      0.00      0.00        22\n",
      "        116       0.00      0.00      0.00        32\n",
      "        117       0.40      0.20      0.27        30\n",
      "        118       0.00      0.00      0.00        21\n",
      "        119       0.67      0.17      0.27        24\n",
      "        120       0.50      0.03      0.06        31\n",
      "        121       0.14      0.06      0.08        18\n",
      "        122       0.71      0.52      0.60        33\n",
      "        123       0.33      0.11      0.16        28\n",
      "        124       0.12      0.04      0.06        25\n",
      "        125       0.18      0.07      0.10        30\n",
      "        126       0.50      0.74      0.60        23\n",
      "        127       0.50      0.36      0.42        22\n",
      "        128       0.33      0.07      0.12        28\n",
      "        129       0.14      0.08      0.11        24\n",
      "        130       0.52      0.45      0.48        29\n",
      "        131       0.21      0.11      0.15        27\n",
      "        132       0.20      0.05      0.08        20\n",
      "        133       0.20      0.04      0.07        25\n",
      "        134       0.29      0.09      0.13        23\n",
      "        135       0.21      0.24      0.22        17\n",
      "        136       0.23      0.12      0.16        24\n",
      "        137       0.00      0.00      0.00        19\n",
      "        138       0.00      0.00      0.00        30\n",
      "        139       0.33      0.11      0.17        27\n",
      "        140       0.00      0.00      0.00        21\n",
      "        141       0.33      0.35      0.34        34\n",
      "        142       0.52      0.46      0.49        24\n",
      "        143       0.33      0.24      0.28        17\n",
      "        144       0.00      0.00      0.00        18\n",
      "        145       0.50      0.08      0.14        24\n",
      "        146       0.90      0.76      0.83        25\n",
      "        147       0.00      0.00      0.00        24\n",
      "        148       0.09      0.04      0.05        26\n",
      "        149       0.54      0.39      0.45        18\n",
      "        150       0.40      0.08      0.13        25\n",
      "        151       0.57      0.25      0.35        32\n",
      "        152       0.38      0.20      0.26        30\n",
      "        153       0.12      0.04      0.06        27\n",
      "        154       0.85      0.38      0.52        45\n",
      "        155       0.33      0.28      0.30        54\n",
      "        156       0.54      0.45      0.49        92\n",
      "        157       0.73      0.62      0.67       183\n",
      "        158       0.55      0.56      0.55        72\n",
      "        159       0.33      0.19      0.24        74\n",
      "        160       0.88      0.88      0.88        94\n",
      "        161       0.49      0.23      0.31       344\n",
      "        162       0.72      0.67      0.69        57\n",
      "        163       0.46      0.29      0.35        38\n",
      "        164       0.59      0.31      0.41        52\n",
      "        165       0.69      0.36      0.47       281\n",
      "        166       0.38      0.32      0.35       789\n",
      "        167       0.37      0.11      0.17       157\n",
      "        168       0.70      0.44      0.54       306\n",
      "        169       0.77      0.93      0.85        44\n",
      "        170       0.52      0.25      0.34       208\n",
      "        171       0.67      0.16      0.26        61\n",
      "        172       0.76      0.54      0.63       102\n",
      "        173       0.30      0.04      0.08        69\n",
      "        174       0.50      0.03      0.05        39\n",
      "        175       0.76      0.64      0.69       303\n",
      "        176       0.50      0.23      0.32        43\n",
      "        177       0.58      0.25      0.35        28\n",
      "        178       0.38      0.14      0.21        85\n",
      "        179       0.74      0.67      0.70       267\n",
      "        180       0.82      0.49      0.61        47\n",
      "        181       0.59      0.39      0.47       113\n",
      "        182       0.82      0.52      0.64        44\n",
      "        183       0.31      0.19      0.24        72\n",
      "        184       0.00      0.00      0.00        40\n",
      "        185       0.33      0.05      0.08        42\n",
      "        186       0.00      0.00      0.00        32\n",
      "        187       0.57      0.53      0.55        40\n",
      "        188       0.20      0.09      0.13        33\n",
      "        189       0.47      0.18      0.26        50\n",
      "        190       0.22      0.06      0.10       140\n",
      "        191       0.30      0.28      0.29        86\n",
      "        192       0.18      0.10      0.12        62\n",
      "        193       0.25      0.13      0.17        45\n",
      "        194       0.74      0.37      0.49        38\n",
      "        195       0.51      0.58      0.54        71\n",
      "        196       0.52      0.35      0.42        62\n",
      "        197       0.54      0.50      0.52        26\n",
      "        198       0.56      0.31      0.40       114\n",
      "        199       0.37      0.35      0.36       217\n",
      "        200       0.46      0.34      0.39       128\n",
      "        201       0.62      0.61      0.61        51\n",
      "        202       0.59      0.54      0.56        61\n",
      "        203       0.27      0.07      0.11        45\n",
      "        204       0.11      0.07      0.09        56\n",
      "        205       0.73      0.48      0.58       615\n",
      "        206       0.55      0.21      0.31        52\n",
      "        207       0.57      0.48      0.52       645\n",
      "        208       0.45      0.32      0.38        28\n",
      "        209       0.07      0.02      0.03        58\n",
      "        210       0.33      0.14      0.20        29\n",
      "        211       0.81      0.37      0.51        60\n",
      "        212       0.38      0.21      0.27        52\n",
      "        213       0.56      0.13      0.21        39\n",
      "        214       0.00      0.00      0.00        40\n",
      "        215       0.62      0.46      0.53        39\n",
      "        216       0.58      0.54      0.56        35\n",
      "        217       0.51      0.39      0.44       216\n",
      "        218       0.75      0.71      0.73        42\n",
      "        219       0.37      0.16      0.22       291\n",
      "        220       0.39      0.24      0.30        29\n",
      "        221       0.79      0.64      0.71       500\n",
      "        222       0.00      0.00      0.00        68\n",
      "        223       0.50      0.11      0.17        38\n",
      "        224       0.46      0.07      0.13        81\n",
      "        225       0.33      0.03      0.05        34\n",
      "        226       0.21      0.15      0.18        52\n",
      "        227       0.43      0.29      0.34        94\n",
      "        228       0.75      0.50      0.60        30\n",
      "        229       0.62      0.51      0.56       613\n",
      "        230       0.67      0.38      0.49        81\n",
      "        231       0.69      0.57      0.63        72\n",
      "        232       0.57      0.50      0.53        56\n",
      "        233       0.52      0.26      0.34        43\n",
      "        234       0.34      0.16      0.22        63\n",
      "        235       0.89      0.77      0.83       553\n",
      "        236       0.35      0.21      0.26        73\n",
      "        237       0.67      0.11      0.19        37\n",
      "        238       0.24      0.07      0.10        90\n",
      "        239       0.61      0.40      0.48        48\n",
      "        240       0.64      0.55      0.59       216\n",
      "        241       0.84      0.68      0.75        38\n",
      "        242       0.77      0.71      0.74       121\n",
      "        243       0.11      0.02      0.03        61\n",
      "        244       0.31      0.32      0.31        38\n",
      "        245       0.30      0.09      0.13        35\n",
      "        246       0.00      0.00      0.00        51\n",
      "        247       0.32      0.17      0.22       266\n",
      "        248       0.78      0.69      0.74        36\n",
      "        249       0.34      0.12      0.18       201\n",
      "\n",
      "avg / total       0.49      0.34      0.39     14953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(feat_test_ngram)\n",
    "\n",
    "print(\"accuracy :\",metrics.accuracy_score(target_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(target_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 scoore :\",metrics.f1_score(target_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(target_test,predictions))\n",
    "print(\"Precision recall report :\\n\",metrics.classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = OneVsRestClassifier(LogisticRegressionCV(Cs=3,  n_jobs=-1, penalty = \"l2\", solver=\"saga\", refit = True, multi_class=\"ovr\"))\n",
    "model2.fit(feat_train_ngram, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.24298034496590454\n",
      "macro f1 score : 0.2500678526254982\n",
      "micro f1 scoore : 0.42046309454150294\n",
      "hamming loss : 0.005561973525872443\n",
      "Precision recall report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        19\n",
      "          1       0.75      0.14      0.23        22\n",
      "          2       0.14      0.12      0.13         8\n",
      "          3       0.85      0.46      0.59        24\n",
      "          4       0.25      0.06      0.10        16\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.00      0.00      0.00        21\n",
      "          7       0.00      0.00      0.00         9\n",
      "          8       0.33      0.06      0.10        17\n",
      "          9       0.00      0.00      0.00        14\n",
      "         10       0.50      0.08      0.13        13\n",
      "         11       0.12      0.06      0.08        18\n",
      "         12       0.00      0.00      0.00        17\n",
      "         13       0.00      0.00      0.00        17\n",
      "         14       0.14      0.05      0.08        19\n",
      "         15       0.00      0.00      0.00        15\n",
      "         16       0.25      0.08      0.12        12\n",
      "         17       0.75      0.14      0.23        22\n",
      "         18       0.29      0.12      0.17        17\n",
      "         19       0.41      0.39      0.40        18\n",
      "         20       0.17      0.06      0.08        18\n",
      "         21       0.60      0.14      0.23        21\n",
      "         22       0.50      0.11      0.18        18\n",
      "         23       0.00      0.00      0.00        16\n",
      "         24       1.00      0.04      0.07        26\n",
      "         25       0.00      0.00      0.00        18\n",
      "         26       0.25      0.06      0.09        18\n",
      "         27       0.67      0.42      0.52        19\n",
      "         28       0.45      0.25      0.32        20\n",
      "         29       0.00      0.00      0.00        15\n",
      "         30       0.29      0.18      0.22        11\n",
      "         31       0.50      0.04      0.08        24\n",
      "         32       0.62      0.28      0.38        18\n",
      "         33       0.00      0.00      0.00        11\n",
      "         34       0.00      0.00      0.00        15\n",
      "         35       0.00      0.00      0.00        12\n",
      "         36       1.00      0.05      0.10        20\n",
      "         37       0.00      0.00      0.00        19\n",
      "         38       0.70      0.37      0.48        19\n",
      "         39       0.50      0.29      0.36        14\n",
      "         40       1.00      0.33      0.50        15\n",
      "         41       0.00      0.00      0.00        21\n",
      "         42       0.40      0.11      0.17        19\n",
      "         43       0.40      0.17      0.24        12\n",
      "         44       0.00      0.00      0.00        18\n",
      "         45       0.50      0.24      0.32        17\n",
      "         46       0.43      0.23      0.30        13\n",
      "         47       0.00      0.00      0.00        20\n",
      "         48       0.75      0.20      0.32        15\n",
      "         49       0.33      0.05      0.09        20\n",
      "         50       0.00      0.00      0.00        29\n",
      "         51       0.12      0.05      0.07        19\n",
      "         52       0.00      0.00      0.00        15\n",
      "         53       0.25      0.04      0.07        23\n",
      "         54       0.50      0.05      0.08        22\n",
      "         55       0.00      0.00      0.00        17\n",
      "         56       0.00      0.00      0.00        20\n",
      "         57       0.33      0.05      0.09        20\n",
      "         58       0.25      0.04      0.07        24\n",
      "         59       0.22      0.09      0.12        23\n",
      "         60       0.14      0.05      0.07        22\n",
      "         61       0.25      0.05      0.08        22\n",
      "         62       0.57      0.55      0.56        22\n",
      "         63       0.50      0.05      0.09        21\n",
      "         64       0.64      0.30      0.41        23\n",
      "         65       0.00      0.00      0.00        19\n",
      "         66       0.00      0.00      0.00        23\n",
      "         67       0.00      0.00      0.00        19\n",
      "         68       0.75      0.17      0.27        18\n",
      "         69       0.00      0.00      0.00        22\n",
      "         70       0.00      0.00      0.00        22\n",
      "         71       0.21      0.14      0.17        21\n",
      "         72       0.00      0.00      0.00        20\n",
      "         73       0.00      0.00      0.00        15\n",
      "         74       0.31      0.38      0.34        24\n",
      "         75       0.57      0.57      0.57        21\n",
      "         76       0.33      0.10      0.16        29\n",
      "         77       0.53      0.33      0.41        24\n",
      "         78       0.46      0.21      0.29        29\n",
      "         79       0.14      0.05      0.07        22\n",
      "         80       0.33      0.06      0.10        17\n",
      "         81       0.50      0.19      0.28        26\n",
      "         82       0.20      0.05      0.08        21\n",
      "         83       0.29      0.06      0.11        31\n",
      "         84       0.14      0.10      0.11        21\n",
      "         85       0.00      0.00      0.00        33\n",
      "         86       0.41      0.36      0.38        39\n",
      "         87       0.40      0.46      0.43        26\n",
      "         88       0.81      0.57      0.67        23\n",
      "         89       0.33      0.04      0.07        26\n",
      "         90       0.20      0.03      0.06        29\n",
      "         91       0.00      0.00      0.00        23\n",
      "         92       0.00      0.00      0.00        25\n",
      "         93       0.00      0.00      0.00        31\n",
      "         94       0.00      0.00      0.00        17\n",
      "         95       0.52      0.58      0.55        26\n",
      "         96       0.80      0.20      0.32        20\n",
      "         97       0.00      0.00      0.00        27\n",
      "         98       0.00      0.00      0.00        30\n",
      "         99       0.17      0.04      0.06        27\n",
      "        100       0.00      0.00      0.00        31\n",
      "        101       0.38      0.19      0.26        26\n",
      "        102       0.67      0.08      0.15        24\n",
      "        103       0.69      0.75      0.72        24\n",
      "        104       0.82      0.47      0.60        30\n",
      "        105       0.00      0.00      0.00        16\n",
      "        106       0.00      0.00      0.00        34\n",
      "        107       0.50      0.22      0.30        23\n",
      "        108       0.56      0.36      0.44        25\n",
      "        109       0.31      0.15      0.20        27\n",
      "        110       0.60      0.12      0.20        25\n",
      "        111       0.30      0.12      0.18        24\n",
      "        112       0.89      0.76      0.82        21\n",
      "        113       0.57      0.36      0.44        33\n",
      "        114       0.33      0.04      0.07        25\n",
      "        115       0.00      0.00      0.00        22\n",
      "        116       0.00      0.00      0.00        32\n",
      "        117       0.40      0.20      0.27        30\n",
      "        118       0.00      0.00      0.00        21\n",
      "        119       0.67      0.17      0.27        24\n",
      "        120       0.50      0.03      0.06        31\n",
      "        121       0.14      0.06      0.08        18\n",
      "        122       0.71      0.52      0.60        33\n",
      "        123       0.33      0.11      0.16        28\n",
      "        124       0.12      0.04      0.06        25\n",
      "        125       0.18      0.07      0.10        30\n",
      "        126       0.50      0.74      0.60        23\n",
      "        127       0.50      0.36      0.42        22\n",
      "        128       0.33      0.07      0.12        28\n",
      "        129       0.14      0.08      0.11        24\n",
      "        130       0.52      0.45      0.48        29\n",
      "        131       0.21      0.11      0.15        27\n",
      "        132       0.20      0.05      0.08        20\n",
      "        133       0.20      0.04      0.07        25\n",
      "        134       0.29      0.09      0.13        23\n",
      "        135       0.21      0.24      0.22        17\n",
      "        136       0.23      0.12      0.16        24\n",
      "        137       0.00      0.00      0.00        19\n",
      "        138       0.00      0.00      0.00        30\n",
      "        139       0.33      0.11      0.17        27\n",
      "        140       0.00      0.00      0.00        21\n",
      "        141       0.33      0.35      0.34        34\n",
      "        142       0.52      0.46      0.49        24\n",
      "        143       0.33      0.24      0.28        17\n",
      "        144       0.00      0.00      0.00        18\n",
      "        145       0.50      0.08      0.14        24\n",
      "        146       0.90      0.76      0.83        25\n",
      "        147       0.00      0.00      0.00        24\n",
      "        148       0.09      0.04      0.05        26\n",
      "        149       0.54      0.39      0.45        18\n",
      "        150       0.40      0.08      0.13        25\n",
      "        151       0.57      0.25      0.35        32\n",
      "        152       0.38      0.20      0.26        30\n",
      "        153       0.12      0.04      0.06        27\n",
      "        154       0.85      0.38      0.52        45\n",
      "        155       0.33      0.28      0.30        54\n",
      "        156       0.54      0.45      0.49        92\n",
      "        157       0.73      0.62      0.67       183\n",
      "        158       0.55      0.56      0.55        72\n",
      "        159       0.33      0.19      0.24        74\n",
      "        160       0.88      0.88      0.88        94\n",
      "        161       0.49      0.23      0.31       344\n",
      "        162       0.72      0.67      0.69        57\n",
      "        163       0.46      0.29      0.35        38\n",
      "        164       0.59      0.31      0.41        52\n",
      "        165       0.69      0.36      0.47       281\n",
      "        166       0.38      0.32      0.35       789\n",
      "        167       0.37      0.11      0.17       157\n",
      "        168       0.70      0.44      0.54       306\n",
      "        169       0.77      0.93      0.85        44\n",
      "        170       0.52      0.25      0.34       208\n",
      "        171       0.67      0.16      0.26        61\n",
      "        172       0.76      0.54      0.63       102\n",
      "        173       0.30      0.04      0.08        69\n",
      "        174       0.50      0.03      0.05        39\n",
      "        175       0.76      0.64      0.69       303\n",
      "        176       0.50      0.23      0.32        43\n",
      "        177       0.58      0.25      0.35        28\n",
      "        178       0.38      0.14      0.21        85\n",
      "        179       0.74      0.67      0.70       267\n",
      "        180       0.82      0.49      0.61        47\n",
      "        181       0.59      0.39      0.47       113\n",
      "        182       0.82      0.52      0.64        44\n",
      "        183       0.31      0.19      0.24        72\n",
      "        184       0.00      0.00      0.00        40\n",
      "        185       0.33      0.05      0.08        42\n",
      "        186       0.00      0.00      0.00        32\n",
      "        187       0.57      0.53      0.55        40\n",
      "        188       0.20      0.09      0.13        33\n",
      "        189       0.47      0.18      0.26        50\n",
      "        190       0.22      0.06      0.10       140\n",
      "        191       0.30      0.28      0.29        86\n",
      "        192       0.18      0.10      0.12        62\n",
      "        193       0.25      0.13      0.17        45\n",
      "        194       0.74      0.37      0.49        38\n",
      "        195       0.51      0.58      0.54        71\n",
      "        196       0.52      0.35      0.42        62\n",
      "        197       0.54      0.50      0.52        26\n",
      "        198       0.56      0.31      0.40       114\n",
      "        199       0.37      0.35      0.36       217\n",
      "        200       0.46      0.34      0.39       128\n",
      "        201       0.62      0.61      0.61        51\n",
      "        202       0.59      0.54      0.56        61\n",
      "        203       0.27      0.07      0.11        45\n",
      "        204       0.11      0.07      0.09        56\n",
      "        205       0.73      0.48      0.58       615\n",
      "        206       0.55      0.21      0.31        52\n",
      "        207       0.57      0.48      0.52       645\n",
      "        208       0.45      0.32      0.38        28\n",
      "        209       0.07      0.02      0.03        58\n",
      "        210       0.33      0.14      0.20        29\n",
      "        211       0.81      0.37      0.51        60\n",
      "        212       0.38      0.21      0.27        52\n",
      "        213       0.56      0.13      0.21        39\n",
      "        214       0.00      0.00      0.00        40\n",
      "        215       0.62      0.46      0.53        39\n",
      "        216       0.58      0.54      0.56        35\n",
      "        217       0.51      0.39      0.44       216\n",
      "        218       0.75      0.71      0.73        42\n",
      "        219       0.37      0.16      0.22       291\n",
      "        220       0.39      0.24      0.30        29\n",
      "        221       0.79      0.64      0.71       500\n",
      "        222       0.00      0.00      0.00        68\n",
      "        223       0.50      0.11      0.17        38\n",
      "        224       0.46      0.07      0.13        81\n",
      "        225       0.33      0.03      0.05        34\n",
      "        226       0.21      0.15      0.18        52\n",
      "        227       0.43      0.29      0.34        94\n",
      "        228       0.75      0.50      0.60        30\n",
      "        229       0.62      0.51      0.56       613\n",
      "        230       0.67      0.38      0.49        81\n",
      "        231       0.69      0.57      0.63        72\n",
      "        232       0.57      0.50      0.53        56\n",
      "        233       0.52      0.26      0.34        43\n",
      "        234       0.34      0.16      0.22        63\n",
      "        235       0.89      0.77      0.83       553\n",
      "        236       0.35      0.21      0.26        73\n",
      "        237       0.67      0.11      0.19        37\n",
      "        238       0.24      0.07      0.10        90\n",
      "        239       0.61      0.40      0.48        48\n",
      "        240       0.64      0.55      0.59       216\n",
      "        241       0.84      0.68      0.75        38\n",
      "        242       0.77      0.71      0.74       121\n",
      "        243       0.11      0.02      0.03        61\n",
      "        244       0.31      0.32      0.31        38\n",
      "        245       0.30      0.09      0.13        35\n",
      "        246       0.00      0.00      0.00        51\n",
      "        247       0.32      0.17      0.22       266\n",
      "        248       0.78      0.69      0.74        36\n",
      "        249       0.34      0.12      0.18       201\n",
      "\n",
      "avg / total       0.49      0.34      0.39     14953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(feat_test_ngram)\n",
    "\n",
    "print(\"accuracy :\",metrics.accuracy_score(target_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(target_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 scoore :\",metrics.f1_score(target_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(target_test,predictions))\n",
    "print(\"Precision recall report :\\n\",metrics.classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
